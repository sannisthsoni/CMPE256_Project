{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 508 ms, sys: 354 ms, total: 862 ms\n",
      "Wall time: 1.81 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:2: DtypeWarning: Columns (11,12) have mixed types. Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.28 s, sys: 610 ms, total: 7.89 s\n",
      "Wall time: 10.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Loading the dataset\n",
    "train = pd.read_csv(\"input/train.csv\")\n",
    "test = pd.read_csv(\"input/test.csv\")\n",
    "train_resource = pd.read_csv(\"input/resources.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 65.9 ms, sys: 28.9 ms, total: 94.7 ms\n",
      "Wall time: 227 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Added a new column for total price per row\n",
    "train_resource['value'] = train_resource['quantity'] * train_resource['price'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.27 s, sys: 79.5 ms, total: 1.35 s\n",
      "Wall time: 1.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_resource_grouped = train_resource.groupby(['id'], as_index=False)[['value']].sum()\n",
    "test_resource_grouped = train_resource.groupby(['id'], as_index=False)[['value']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 495 ms, sys: 80.5 ms, total: 576 ms\n",
      "Wall time: 574 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Train & Test dataset - resource part added\n",
    "train_joined = pd.merge(train,train_resource_grouped,on='id')\n",
    "test_joined = pd.merge(test,test_resource_grouped,on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 112 ms, sys: 346 µs, total: 112 ms\n",
      "Wall time: 110 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Replacing NaN with empty string\n",
    "#Addding essay 1 & 3\n",
    "#Adding essay 2 & 4\n",
    "#Effectively every row will have 2 essay columns\n",
    "train_joined['projectessay_1_3'] = train_joined['project_essay_1']+train_joined['project_essay_3'].replace(np.nan, '', regex=True)\n",
    "train_joined['projectessay_2_4'] = train_joined['project_essay_2']+train_joined['project_essay_4'].replace(np.nan, '', regex=True)\n",
    "test_joined['projectessay_1_3'] = test_joined['project_essay_1']+test_joined['project_essay_3'].replace(np.nan, '', regex=True)\n",
    "test_joined['projectessay_2_4'] = test_joined['project_essay_2']+test_joined['project_essay_4'].replace(np.nan, '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 265 ms, sys: 23.6 ms, total: 288 ms\n",
      "Wall time: 288 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Dropping id and previous essay columns\n",
    "columns_to_remove = [\"id\",\"project_essay_1\",\"project_essay_2\",\"project_essay_3\",\"project_essay_4\"]\n",
    "train_joined.drop(columns_to_remove,inplace=True,axis=1)\n",
    "test_joined.drop(columns_to_remove,inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6 µs, sys: 1e+03 ns, total: 7 µs\n",
      "Wall time: 10 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Classifying acc to the type of cols\n",
    "categorical_columns = ['teacher_prefix','school_state', 'project_grade_category',\n",
    "                       'project_subject_categories', 'project_subject_subcategories']\n",
    "non_cat_columns = [\"project_submitted_datetime\",\n",
    "                   \"teacher_number_of_previously_posted_projects\",\"value\"]\n",
    "text_columns = [\"project_title\",\"project_resource_summary\",\n",
    "                \"projectessay_1_3\",\"projectessay_2_4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42.8 ms, sys: 0 ns, total: 42.8 ms\n",
      "Wall time: 42 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# y (aka target var) is train['project_is_approved']\n",
    "train_cat = train_joined[categorical_columns]\n",
    "train_non_cat = train_joined[non_cat_columns]\n",
    "train_text = train_joined[text_columns]\n",
    "test_cat = test_joined[categorical_columns]\n",
    "test_non_cat = test_joined[non_cat_columns]\n",
    "test_text = test_joined[text_columns]\n",
    "y = train_joined['project_is_approved']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.03 s, sys: 87.5 ms, total: 1.12 s\n",
      "Wall time: 1.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_cat = pd.get_dummies(train_cat)\n",
    "test_cat = pd.get_dummies(test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 71.2 ms, sys: 164 ms, total: 235 ms\n",
      "Wall time: 237 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_columns = test_cat.columns \n",
    "train_columns = train_cat.columns\n",
    "all_columns = train_columns.union(test_columns)\n",
    "train_add_columns = all_columns.difference(train_columns)\n",
    "test_add_columns = all_columns.difference(test_columns)\n",
    "test_copy = test_cat\n",
    "test_cat = pd.concat([test_copy , test_copy.reindex(columns = test_add_columns, fill_value = 0.0)], axis = 1)\n",
    "train_copy = train_cat\n",
    "train_cat = pd.concat([train_copy , train_copy.reindex(columns = train_add_columns, fill_value = 0.0)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 145 ms, sys: 3.51 ms, total: 148 ms\n",
      "Wall time: 166 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sannisth/venv/lib/python3.5/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/sannisth/venv/lib/python3.5/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Convert column to datetime column\n",
    "train_non_cat[\"project_submitted_datetime\"] = pd.to_datetime(train_non_cat[\"project_submitted_datetime\"])\n",
    "test_non_cat[\"project_submitted_datetime\"] = pd.to_datetime(test_non_cat[\"project_submitted_datetime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sannisth/venv/lib/python3.5/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/sannisth/venv/lib/python3.5/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.77 s, sys: 16.3 ms, total: 1.78 s\n",
      "Wall time: 1.79 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sannisth/venv/lib/python3.5/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/sannisth/venv/lib/python3.5/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Get month year from the datetome column\n",
    "train_non_cat[\"Project_submitted_month\"] = train_non_cat[\"project_submitted_datetime\"].map(lambda x: x.month)\n",
    "train_non_cat[\"Project_submitted_year\"] = train_non_cat[\"project_submitted_datetime\"].map(lambda x: x.year)\n",
    "test_non_cat[\"Project_submitted_month\"] = test_non_cat[\"project_submitted_datetime\"].map(lambda x: x.month)\n",
    "test_non_cat[\"Project_submitted_year\"] = test_non_cat[\"project_submitted_datetime\"].map(lambda x: x.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 83.8 ms, sys: 0 ns, total: 83.8 ms\n",
      "Wall time: 82 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sannisth/venv/lib/python3.5/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/sannisth/venv/lib/python3.5/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_non_cat.drop([\"project_submitted_datetime\"],inplace=True,axis=1)\n",
    "test_non_cat.drop([\"project_submitted_datetime\"],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 µs, sys: 1e+03 ns, total: 9 µs\n",
      "Wall time: 13.4 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "std = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.5 ms, sys: 276 µs, total: 26.8 ms\n",
      "Wall time: 26.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_non_cat_scaled = pd.DataFrame(std.fit_transform(train_non_cat),columns=train_non_cat.columns)\n",
    "test_non_cat_scaled = pd.DataFrame(std.fit_transform(test_non_cat),columns=test_non_cat.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack, csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 64 µs, sys: 0 ns, total: 64 µs\n",
      "Wall time: 70.1 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "word_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    lowercase=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\w{1,}',\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 1),\n",
    "    max_features=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 4s, sys: 1.08 s, total: 2min 5s\n",
      "Wall time: 2min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vectorized_columns = []\n",
    "vectorized_columns_test = []\n",
    "for text_column in text_columns:\n",
    "    word_vectorizer.fit(pd.concat([train_text[text_column],test_text[text_column]]))\n",
    "    vectorized_columns.append(word_vectorizer.transform(train_text[text_column]))\n",
    "    vectorized_columns_test.append(word_vectorizer.transform(test_text[text_column]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.16 s, sys: 868 ms, total: 5.03 s\n",
      "Wall time: 5.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_features = hstack(vectorized_columns+[csr_matrix(train_non_cat_scaled)]+[csr_matrix(train_cat)], 'csr')\n",
    "test_features = hstack(vectorized_columns_test+[csr_matrix(test_non_cat_scaled)]+[csr_matrix(test_cat)], 'csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.52 s, sys: 248 ms, total: 2.77 s\n",
      "Wall time: 3.42 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "rfc.fit(train_features,y)\n",
    "\n",
    "predicted_prolly_rfc = rfc.predict_proba(test_features)\n",
    "result_rfc = pd.DataFrame.from_dict({'id':test['id']})\n",
    "result_rfc['project_is_approved'] = predicted_prolly_rfc[:,1]\n",
    "result_rfc.to_csv(\"submission_rfc.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sannisth/venv/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.34 s, sys: 11.7 ms, total: 1.36 s\n",
      "Wall time: 2.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgdclassifier = SGDClassifier(loss=\"log\",penalty=\"l2\")\n",
    "sgdclassifier.fit(train_features,y)\n",
    "predicted_prolly = sgdclassifier.predict_proba(test_features)\n",
    "#result = pd.DataFrame.from_dict({'id':test['id']})\n",
    "#result['project_is_approved'] ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 243 ms, sys: 76 µs, total: 243 ms\n",
      "Wall time: 245 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = pd.DataFrame.from_dict({'id':test['id']})\n",
    "result['project_is_approved'] = predicted_prolly[:,1]\n",
    "result.to_csv(\"submission_sgd.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sannisth/venv/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 2s, sys: 92.2 ms, total: 1min 2s\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(n_jobs=-1)\n",
    "model.fit(train_features,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 284 ms, sys: 159 µs, total: 285 ms\n",
      "Wall time: 285 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predicted_proba = model.predict_proba(test_features)\n",
    "submission = pd.DataFrame.from_dict({'id': test['id']})\n",
    "submission['project_is_approved'] = predicted_proba[:,1]\n",
    "submission.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model using Light GBM and finding AUC(Area Under Curve)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[25]\tvalid_0's auc: 0.678753\n",
      "[50]\tvalid_0's auc: 0.688007\n",
      "[75]\tvalid_0's auc: 0.692977\n",
      "[100]\tvalid_0's auc: 0.702708\n",
      "[125]\tvalid_0's auc: 0.710777\n",
      "[150]\tvalid_0's auc: 0.71666\n",
      "[175]\tvalid_0's auc: 0.72158\n",
      "[200]\tvalid_0's auc: 0.726588\n",
      "[225]\tvalid_0's auc: 0.730336\n",
      "[250]\tvalid_0's auc: 0.734045\n",
      "[275]\tvalid_0's auc: 0.736989\n",
      "[300]\tvalid_0's auc: 0.739186\n",
      "[325]\tvalid_0's auc: 0.741367\n",
      "[350]\tvalid_0's auc: 0.743142\n",
      "[375]\tvalid_0's auc: 0.744646\n",
      "[400]\tvalid_0's auc: 0.745842\n",
      "[425]\tvalid_0's auc: 0.747229\n",
      "[450]\tvalid_0's auc: 0.748748\n",
      "[475]\tvalid_0's auc: 0.750011\n",
      "[500]\tvalid_0's auc: 0.75085\n",
      "[525]\tvalid_0's auc: 0.75169\n",
      "[550]\tvalid_0's auc: 0.752704\n",
      "[575]\tvalid_0's auc: 0.753547\n",
      "[600]\tvalid_0's auc: 0.753945\n",
      "[625]\tvalid_0's auc: 0.754923\n",
      "[650]\tvalid_0's auc: 0.755393\n",
      "[675]\tvalid_0's auc: 0.756066\n",
      "[700]\tvalid_0's auc: 0.756832\n",
      "[725]\tvalid_0's auc: 0.757521\n",
      "[750]\tvalid_0's auc: 0.757938\n",
      "[775]\tvalid_0's auc: 0.75827\n",
      "[800]\tvalid_0's auc: 0.758821\n",
      "[825]\tvalid_0's auc: 0.75925\n",
      "[850]\tvalid_0's auc: 0.759499\n",
      "[875]\tvalid_0's auc: 0.759997\n",
      "[900]\tvalid_0's auc: 0.7604\n",
      "[925]\tvalid_0's auc: 0.760797\n",
      "[950]\tvalid_0's auc: 0.761024\n",
      "[975]\tvalid_0's auc: 0.761286\n",
      "[1000]\tvalid_0's auc: 0.761549\n",
      "[1025]\tvalid_0's auc: 0.761799\n",
      "[1050]\tvalid_0's auc: 0.762192\n",
      "[1075]\tvalid_0's auc: 0.762448\n",
      "[1100]\tvalid_0's auc: 0.762807\n",
      "[1125]\tvalid_0's auc: 0.762863\n",
      "[1150]\tvalid_0's auc: 0.763276\n",
      "[1175]\tvalid_0's auc: 0.763524\n",
      "[1200]\tvalid_0's auc: 0.763692\n",
      "[1225]\tvalid_0's auc: 0.764061\n",
      "[1250]\tvalid_0's auc: 0.764369\n",
      "[1275]\tvalid_0's auc: 0.764642\n",
      "[1300]\tvalid_0's auc: 0.764755\n",
      "[1325]\tvalid_0's auc: 0.764858\n",
      "[1350]\tvalid_0's auc: 0.764977\n",
      "[1375]\tvalid_0's auc: 0.765072\n",
      "[1400]\tvalid_0's auc: 0.765144\n",
      "[1425]\tvalid_0's auc: 0.765422\n",
      "[1450]\tvalid_0's auc: 0.765658\n",
      "[1475]\tvalid_0's auc: 0.765674\n",
      "[1500]\tvalid_0's auc: 0.765789\n",
      "[1525]\tvalid_0's auc: 0.765871\n",
      "[1550]\tvalid_0's auc: 0.766119\n",
      "[1575]\tvalid_0's auc: 0.766264\n",
      "[1600]\tvalid_0's auc: 0.766452\n",
      "[1625]\tvalid_0's auc: 0.766493\n",
      "[1650]\tvalid_0's auc: 0.766563\n",
      "[1675]\tvalid_0's auc: 0.766658\n",
      "[1700]\tvalid_0's auc: 0.766679\n",
      "[1725]\tvalid_0's auc: 0.766645\n",
      "[1750]\tvalid_0's auc: 0.766746\n",
      "[1775]\tvalid_0's auc: 0.76685\n",
      "[1800]\tvalid_0's auc: 0.766968\n",
      "[1825]\tvalid_0's auc: 0.767053\n",
      "[1850]\tvalid_0's auc: 0.767167\n",
      "[1875]\tvalid_0's auc: 0.767352\n",
      "[1900]\tvalid_0's auc: 0.767584\n",
      "[1925]\tvalid_0's auc: 0.767704\n",
      "[1950]\tvalid_0's auc: 0.767885\n",
      "[1975]\tvalid_0's auc: 0.767993\n",
      "[2000]\tvalid_0's auc: 0.767977\n",
      "[2025]\tvalid_0's auc: 0.768138\n",
      "[2050]\tvalid_0's auc: 0.768184\n",
      "[2075]\tvalid_0's auc: 0.768266\n",
      "[2100]\tvalid_0's auc: 0.768332\n",
      "[2125]\tvalid_0's auc: 0.768484\n",
      "[2150]\tvalid_0's auc: 0.768525\n",
      "[2175]\tvalid_0's auc: 0.768551\n",
      "[2200]\tvalid_0's auc: 0.768618\n",
      "[2225]\tvalid_0's auc: 0.768716\n",
      "[2250]\tvalid_0's auc: 0.768839\n",
      "[2275]\tvalid_0's auc: 0.7687\n",
      "[2300]\tvalid_0's auc: 0.768739\n",
      "[2325]\tvalid_0's auc: 0.768846\n",
      "[2350]\tvalid_0's auc: 0.768924\n",
      "[2375]\tvalid_0's auc: 0.768989\n",
      "[2400]\tvalid_0's auc: 0.769097\n",
      "[2425]\tvalid_0's auc: 0.769159\n",
      "[2450]\tvalid_0's auc: 0.769104\n",
      "[2475]\tvalid_0's auc: 0.769286\n",
      "[2500]\tvalid_0's auc: 0.76927\n",
      "[2525]\tvalid_0's auc: 0.769337\n",
      "[2550]\tvalid_0's auc: 0.769362\n",
      "[2575]\tvalid_0's auc: 0.769375\n",
      "[2600]\tvalid_0's auc: 0.769414\n",
      "[2625]\tvalid_0's auc: 0.769481\n",
      "[2650]\tvalid_0's auc: 0.769458\n",
      "[2675]\tvalid_0's auc: 0.769358\n",
      "[2700]\tvalid_0's auc: 0.769598\n",
      "[2725]\tvalid_0's auc: 0.769605\n",
      "[2750]\tvalid_0's auc: 0.769717\n",
      "[2775]\tvalid_0's auc: 0.769748\n",
      "[2800]\tvalid_0's auc: 0.769709\n",
      "[2825]\tvalid_0's auc: 0.769735\n",
      "[2850]\tvalid_0's auc: 0.769921\n",
      "[2875]\tvalid_0's auc: 0.769787\n",
      "[2900]\tvalid_0's auc: 0.769767\n",
      "[2925]\tvalid_0's auc: 0.769757\n",
      "Early stopping, best iteration is:\n",
      "[2849]\tvalid_0's auc: 0.769925\n",
      "AUC: 0.7699246877179493\n",
      "CPU times: user 1h 44min 55s, sys: 20.2 s, total: 1h 45min 15s\n",
      "Wall time: 30min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Trying LightGBM\n",
    "print(\"Building model using Light GBM and finding AUC(Area Under Curve)\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_l, X_valid_l, y_train_l, y_valid_l = train_test_split(train_features, y, test_size=0.10, random_state=2018)\n",
    "params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'max_depth': 7,\n",
    "        'num_leaves': 32,\n",
    "        'learning_rate': 0.02,\n",
    "        'feature_fraction': 0.80,\n",
    "        'bagging_fraction': 0.80,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': 0,\n",
    "        'lambda_l2': 1,\n",
    "    }  \n",
    "\n",
    "import lightgbm as lgb\n",
    "evals_result = {}  # to record eval results for plotting\n",
    "model_lgb = lgb.train(\n",
    "        params,\n",
    "        lgb.Dataset(X_train_l, y_train_l),\n",
    "        num_boost_round=10000,\n",
    "        valid_sets=[lgb.Dataset(X_valid_l, y_valid_l)],\n",
    "        early_stopping_rounds=100,\n",
    "        evals_result=evals_result,\n",
    "        verbose_eval=25)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "valid_preds_lgb = model_lgb.predict(X_valid_l, num_iteration=model_lgb.best_iteration)\n",
    "test_preds = model_lgb.predict(test_features, num_iteration=model_lgb.best_iteration)\n",
    "auc = roc_auc_score(y_valid_l, valid_preds_lgb)\n",
    "print('AUC:',auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 247 ms, sys: 7.97 ms, total: 255 ms\n",
      "Wall time: 609 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "submission1 = pd.DataFrame.from_dict({'id': test['id']})\n",
    "submission1['project_is_approved'] = test_preds\n",
    "submission1.to_csv(\"submission1.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.611914\tvalid-auc:0.609135\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 100 rounds.\n",
      "[50]\ttrain-auc:0.78454\tvalid-auc:0.727543\n",
      "[100]\ttrain-auc:0.823112\tvalid-auc:0.737252\n",
      "[150]\ttrain-auc:0.848884\tvalid-auc:0.740282\n",
      "[200]\ttrain-auc:0.870085\tvalid-auc:0.742116\n",
      "[250]\ttrain-auc:0.886647\tvalid-auc:0.742301\n",
      "[300]\ttrain-auc:0.900448\tvalid-auc:0.743686\n",
      "[350]\ttrain-auc:0.911879\tvalid-auc:0.744054\n",
      "[400]\ttrain-auc:0.922382\tvalid-auc:0.744138\n",
      "Stopping. Best iteration:\n",
      "[335]\ttrain-auc:0.908244\tvalid-auc:0.744598\n",
      "\n",
      "AUC: 0.7438332337078135\n",
      "CPU times: user 38min 44s, sys: 4.07 s, total: 38min 48s\n",
      "Wall time: 10min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Trying XGBoost\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "xgb_params = {'eta': 0.2, \n",
    "                  'max_depth': 5, \n",
    "                  'subsample': 0.8, \n",
    "                  'colsample_bytree': 0.8, \n",
    "                  'objective': 'binary:logistic', \n",
    "                  'eval_metric': 'auc', \n",
    "                  'seed': 1234\n",
    "                 }\n",
    "X_train_x, X_valid_x, y_train_x, y_valid_x = train_test_split(train_features, y, test_size=0.33, random_state=2018)\n",
    "d_train = xgb.DMatrix(X_train_x, y_train_x)\n",
    "d_valid = xgb.DMatrix(X_valid_x, y_valid_x)\n",
    "d_test = xgb.DMatrix(test_features)\n",
    "watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "model_xgb = xgb.train(xgb_params, d_train, 500, watchlist, verbose_eval=50, early_stopping_rounds=100)\n",
    "xgb_pred_test = model_xgb.predict(d_test)\n",
    "xgb_pred_valid = model_xgb.predict(d_valid)\n",
    "auc = roc_auc_score(y_valid_x, xgb_pred_valid)\n",
    "print('AUC:',auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "submission2 = pd.DataFrame.from_dict({'id': test['id']})\n",
    "submission2['project_is_approved'] = xgb_pred_test\n",
    "submission2.to_csv(\"submission2.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projectname",
   "language": "python",
   "name": "projectname"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
